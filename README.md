# 🚀 My Curated Hub of Datasets & ML Prep Scripts 🚀

Welcome to my personal collection of datasets and the Python scripts I use to wrangle, clean, and prepare them for machine learning. This repository serves as a centralized location for the data I've gathered and the workflows I've developed for various ML experiments.

## 📂 Repository Structure

Here’s a breakdown of what you'll find inside:

### └── `Gemma3n-tune/`

This directory is dedicated to datasets and preparation scripts specifically for fine-tuning the Gemma family of models.

#### &nbsp;&nbsp;&nbsp;&nbsp;└── `acci-wounds/`

This is a specialized dataset I've compiled containing images and textual data related to **accidental wounds**. The primary goal is to use this data to fine-tune models for tasks such as:

*   **Medical Image Analysis:** Identifying and classifying different types of wounds.
*   **Multimodal AI:** Training models that can understand both the visual and textual context of medical injuries.

The scripts within this folder are tailored to process this specific dataset, handling tasks like renaming files, merging data from different sources (`.csv`, `.jsonl`), and formatting it into a final, model-ready state.

### └── `dump/`

This is my digital scratchpad. It contains miscellaneous scripts, temporary files, and other works-in-progress that haven't found a permanent home yet. Feel free to browse, but be aware that things might be in a state of flux here!

## 🤝 Contributing

While this is a personal repository, I'm always open to collaboration and suggestions. If you have ideas for new datasets, improvements for scripts, or find anything interesting, feel free to open an issue!
